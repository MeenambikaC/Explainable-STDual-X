{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3437053,"sourceType":"datasetVersion","datasetId":2070758}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Proposed Model Architecture\n\nThis notebook is to try the proposed model architecure with cross-sensor-attention for PAMAP2 dataset and evaluate their performance","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# Standard library imports\nimport inspect\nimport logging\nimport math\nimport os\nimport pickle\nimport random\nimport shutil\nimport subprocess\nimport time\n\n# Third-party imports\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import (\n    accuracy_score,\n    confusion_matrix,\n    f1_score,\n    precision_score,\n    recall_score,\n    silhouette_score,\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport wandb\nfrom sklearn.manifold import TSNE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:35:56.696818Z","iopub.execute_input":"2025-05-16T03:35:56.697070Z","iopub.status.idle":"2025-05-16T03:36:03.243758Z","shell.execute_reply.started":"2025-05-16T03:35:56.697043Z","shell.execute_reply":"2025-05-16T03:36:03.242871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clear_working_directory():\n    directory_to_clear = '/kaggle/working/'\n\n    for filename in os.listdir(directory_to_clear):\n        file_path = os.path.join(directory_to_clear, filename)\n        try:\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)  \n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)   \n        except Exception as e:\n            print(f\"Failed to remove {file_path}. Reason: {e}\")\n            \nclear_working_directory()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:03.244632Z","iopub.execute_input":"2025-05-16T03:36:03.244872Z","iopub.status.idle":"2025-05-16T03:36:03.250138Z","shell.execute_reply.started":"2025-05-16T03:36:03.244838Z","shell.execute_reply":"2025-05-16T03:36:03.249185Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyper-paramters","metadata":{}},{"cell_type":"code","source":"EPOCHS = 70\nBATCH_SIZE = 128\nIMU_FEATURE_COUNT = 108\nCLASSES = 12\nLEARNING_RATE = 0.001\nSEQUENCE_LENGTH= 120\nOVERLAP = 40\n\n\nBEST_ACCURACY = 0.0\nBEST_LOSS = 1000\n\nMAX_SAVED_MODELS = 10\n\n# WEIGHT_CLASSIFIER_LOSS  = 1 \n\n# WEIGHT_TRIPLET_LOSS = 0\nMIN_LR = 0.001\nLR_FACTOR = 0.4\nPATIENCE = 5\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:03.250997Z","iopub.execute_input":"2025-05-16T03:36:03.251278Z","iopub.status.idle":"2025-05-16T03:36:03.330786Z","shell.execute_reply.started":"2025-05-16T03:36:03.251245Z","shell.execute_reply":"2025-05-16T03:36:03.330053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.login(key=\"59bd7d0ab50dc7224820069ac4ab705f01fa85d8\")\n# wandb.login(key=\"b15ee5c84e51289dd7b5dd11ea38949957d772f9\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:03.332277Z","iopub.execute_input":"2025-05-16T03:36:03.332549Z","iopub.status.idle":"2025-05-16T03:36:13.028346Z","shell.execute_reply.started":"2025-05-16T03:36:03.332527Z","shell.execute_reply":"2025-05-16T03:36:13.027675Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.init(\n    project=\"PAMAP2 - Cross Sensor Attention - Overall\",\n    name = \"Version-08\",\n    # notes = \"test nordic walking\",\n\n    config={\n        \"architecture\": \"Transformer\",\n        \"dataset\": \"PAMAP2\",\n        \"epochs\": EPOCHS,\n        # \"epoch_batch_count\" : EPOCH_BATCH_COUNT,\n        \"batch_size\" : BATCH_SIZE,\n        \"imu_feature_count\" : IMU_FEATURE_COUNT,\n        \"classes\" : CLASSES,\n        \"learning_rate\" : LEARNING_RATE,\n#         \"WEIGHT_CLASSIFIER_LOSS\" : WEIGHT_CLASSIFIER_LOSS,\n#         \"WEIGHT_TRIPLET_LOSS\" : WEIGHT_TRIPLET_LOSS,\n        \"Sequence_length\":SEQUENCE_LENGTH,\n        \"Overlap\":OVERLAP\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:13.029811Z","iopub.execute_input":"2025-05-16T03:36:13.030236Z","iopub.status.idle":"2025-05-16T03:36:20.662058Z","shell.execute_reply.started":"2025-05-16T03:36:13.030211Z","shell.execute_reply":"2025-05-16T03:36:20.661355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Activities in dataset","metadata":{}},{"cell_type":"code","source":"activityIDdict  = {0: 'transient',\n              1: 'lying',\n              2: 'sitting',\n              3: 'standing',\n              4: 'walking',\n              5: 'running',\n              6: 'cycling',\n              7: 'Nordic_walking',\n              9: 'watching_TV',\n              10: 'computer_work',\n              11: 'car driving',\n              12: 'ascending_stairs',\n              13: 'descending_stairs',\n              16: 'vacuum_cleaning',\n              17: 'ironing',\n              18: 'folding_laundry',\n              19: 'house_cleaning',\n              20: 'playing_soccer',\n              24: 'rope_jumping' }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.662786Z","iopub.execute_input":"2025-05-16T03:36:20.663053Z","iopub.status.idle":"2025-05-16T03:36:20.667553Z","shell.execute_reply.started":"2025-05-16T03:36:20.663031Z","shell.execute_reply":"2025-05-16T03:36:20.666691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 12 classes","metadata":{}},{"cell_type":"code","source":"all_list = [1, 2, 3, 17, 16, 12, 13, 4, 7, 6, 5, 24]\n\nactivity_names = [\n    'lying',\n    'sitting',\n    'standing',\n    'ironing',\n    'vacuum_cleaning',\n    'ascending_stairs',\n    'descending_stairs',\n    'walking',\n    'Nordic_walking',\n    'cycling',\n    'running',\n    'rope_jumping'\n]\n\n\n# Map activities to IDs dynamically\nactivity_id_mapping = {key: activity for key, activity in zip(all_list, activity_names)}\n\n# Arrange all_list based on the shuffled activity names\nall_list = list(activity_id_mapping.keys())\n\n# Output the results\nprint(\"Shuffled Activity Names:\", activity_names)\nprint(\"Activity ID Mapping:\", activity_id_mapping)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.668372Z","iopub.execute_input":"2025-05-16T03:36:20.668657Z","iopub.status.idle":"2025-05-16T03:36:20.686237Z","shell.execute_reply.started":"2025-05-16T03:36:20.668610Z","shell.execute_reply":"2025-05-16T03:36:20.685536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LOG_LEVEL = \"INFO\" # Adjust this to \"DEBUG\", \"INFO\", \"WARNING\" or \"ERROR\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.686962Z","iopub.execute_input":"2025-05-16T03:36:20.687272Z","iopub.status.idle":"2025-05-16T03:36:20.697694Z","shell.execute_reply.started":"2025-05-16T03:36:20.687242Z","shell.execute_reply":"2025-05-16T03:36:20.696866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Map log level strings to logging constants\nlog_levels = {\n    \"DEBUG\": logging.DEBUG,\n    \"INFO\": logging.INFO,\n    \"WARNING\": logging.WARNING,\n    \"ERROR\": logging.ERROR\n}\nset_log_level = log_levels.get(LOG_LEVEL, logging.INFO)  \n\n\nlogging.basicConfig(\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    level=set_log_level,\n    datefmt=\"%Y-%m-%d %H:%M:%S\"\n)\n\ndef log_message(level, message, block=None, log_title=\"\", caller_frame=None):\n    \"\"\"\n    Logs a message with a specific logging level and additional details.\n    \n    Args:\n        level (str): Logging level ('DEBUG', 'INFO', 'WARNING', 'ERROR').\n        message (str): The message to log.\n        block (str, optional): Additional block/section name for context.\n        log_title (str): Title to specify log type.\n        caller_frame (frame, optional): Frame object of the calling function.\n    \"\"\"\n    \n    line_number = caller_frame.f_lineno if caller_frame else \"N/A\"\n    function_name = caller_frame.f_code.co_name if caller_frame else \"N/A\"\n\n    \n    formatted_title = log_title.ljust(7)  \n    formatted_line = f\"Line {line_number}\".ljust(8) \n\n\n    log_msg = f\"{formatted_title} | {formatted_line} | {message}\"\n    if block:\n        log_msg += f\" - Block: {block}\"\n\n\n    should_print = log_levels[level.upper()] >= set_log_level\n\n    if should_print:\n        print(log_msg)  \n\n    if level.upper() == \"DEBUG\":\n        logging.debug(log_msg)\n    elif level.upper() == \"INFO\":\n        logging.info(log_msg)\n    elif level.upper() == \"WARNING\":\n        logging.warning(log_msg)\n    elif level.upper() == \"ERROR\":\n        logging.error(log_msg)\n    else:\n        logging.info(\"Unknown log level specified.\")\n\n\ndef print_log(message, block=None):\n    caller_frame = inspect.currentframe().f_back\n    log_message(\"INFO\", message, block, log_title=\"INFO\", caller_frame=caller_frame)\n\ndef debug_log(message, block=None):\n    caller_frame = inspect.currentframe().f_back\n    log_message(\"DEBUG\", message, block, log_title=\"DEBUG\", caller_frame=caller_frame)\n\ndef warn_log(message, block=None):\n    caller_frame = inspect.currentframe().f_back\n    log_message(\"WARNING\", message, block, log_title=\"WARNING\", caller_frame=caller_frame)\n\ndef error_log(message, block=None):\n    caller_frame = inspect.currentframe().f_back\n    log_message(\"ERROR\", message, block, log_title=\"ERROR\", caller_frame=caller_frame)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.698395Z","iopub.execute_input":"2025-05-16T03:36:20.698614Z","iopub.status.idle":"2025-05-16T03:36:20.713738Z","shell.execute_reply.started":"2025-05-16T03:36:20.698595Z","shell.execute_reply":"2025-05-16T03:36:20.713088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\nlist_of_files = ['/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject101.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject102.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject103.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject104.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject105.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject106.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject107.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject108.dat',\n                 '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol/subject109.dat' ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.714493Z","iopub.execute_input":"2025-05-16T03:36:20.714717Z","iopub.status.idle":"2025-05-16T03:36:20.732624Z","shell.execute_reply.started":"2025-05-16T03:36:20.714694Z","shell.execute_reply":"2025-05-16T03:36:20.731868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"subjectID = [1,2,3,4,5,6,7,8,9]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.733310Z","iopub.execute_input":"2025-05-16T03:36:20.733526Z","iopub.status.idle":"2025-05-16T03:36:20.746952Z","shell.execute_reply.started":"2025-05-16T03:36:20.733495Z","shell.execute_reply":"2025-05-16T03:36:20.746183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colNames = [\"timestamp\", \"activityID\",\"heartrate\"]\nIMUhand = ['handTemperature', \n           'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n           'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n           'handGyro_1', 'handGyro_2', 'handGyro_3', \n           'handMagne_1', 'handMagne_2', 'handMagne_3',\n           'handOrientation_1', 'handOrientation_2', 'handOrientation_3', 'handOrientation_4']\n\nIMUchest = ['chestTemperature', \n           'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n           'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n           'chestGyro_1', 'chestGyro_2', 'chestGyro_3', \n           'chestMagne_1', 'chestMagne_2', 'chestMagne_3',\n           'chestOrientation_1', 'chestOrientation_2', 'chestOrientation_3', 'chestOrientation_4']\n\nIMUankle = ['ankleTemperature', \n           'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n           'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n           'ankleGyro_1', 'ankleGyro_2', 'ankleGyro_3', \n           'ankleMagne_1', 'ankleMagne_2', 'ankleMagne_3',\n           'ankleOrientation_1', 'ankleOrientation_2', 'ankleOrientation_3', 'ankleOrientation_4']\n\ncolumns = colNames + IMUhand + IMUchest + IMUankle\n\nlen(columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.747886Z","iopub.execute_input":"2025-05-16T03:36:20.748219Z","iopub.status.idle":"2025-05-16T03:36:20.764372Z","shell.execute_reply.started":"2025-05-16T03:36:20.748189Z","shell.execute_reply":"2025-05-16T03:36:20.763601Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"code","source":"directory= '/kaggle/input/pampa2/PAMAP2_Dataset/Protocol'\n\ndataCollection = pd.DataFrame()\ndata_dict={}\nfor filename in os.listdir(directory):\n    file = os.path.join(directory, filename)\n    print(file)\n    procData = pd.read_table(file, header=None, sep='\\s+')\n    procData.columns = columns\n    procData['subject_id'] = int(file[-5])\n    dataCollection = pd.concat([dataCollection, procData], ignore_index=True)\n\ndataCollection.reset_index(drop=True, inplace=True)\ndataCollection.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:20.767210Z","iopub.execute_input":"2025-05-16T03:36:20.767424Z","iopub.status.idle":"2025-05-16T03:36:57.649553Z","shell.execute_reply.started":"2025-05-16T03:36:20.767405Z","shell.execute_reply":"2025-05-16T03:36:57.648724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dataCleaning(dataCollection):\n        dataCollection = dataCollection.drop(['handOrientation_1', 'handOrientation_2', 'handOrientation_3', 'handOrientation_4',\n                                             'chestOrientation_1', 'chestOrientation_2', 'chestOrientation_3', 'chestOrientation_4',\n                                             'ankleOrientation_1', 'ankleOrientation_2', 'ankleOrientation_3', 'ankleOrientation_4','chestTemperature',\n           'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3','ankleTemperature', \n           'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n           'handAcc6_1','handAcc6_2','handAcc6_3',\n           'heartrate','handTemperature','timestamp'\n                                             ],\n                                             axis = 1)  # removal of orientation columns as they are not needed\n        dataCollection = dataCollection.drop(dataCollection[dataCollection.activityID == 0].index) #removal of any row of activity 0 as it is transient activity which it is not used\n        dataCollection = dataCollection.apply(pd.to_numeric, errors = 'coerce') #removal of non numeric data in cells\n        dataCollection = dataCollection.interpolate() #removal of any remaining NaN value cells by constructing new data points in known set of data points\n        \n        return dataCollection","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:57.651176Z","iopub.execute_input":"2025-05-16T03:36:57.651373Z","iopub.status.idle":"2025-05-16T03:36:57.656709Z","shell.execute_reply.started":"2025-05-16T03:36:57.651355Z","shell.execute_reply":"2025-05-16T03:36:57.655875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataCol = dataCleaning(dataCollection)\ndataCol.reset_index(drop = True, inplace = True)\ndataCol.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:36:57.657533Z","iopub.execute_input":"2025-05-16T03:36:57.657798Z","iopub.status.idle":"2025-05-16T03:37:01.279860Z","shell.execute_reply.started":"2025-05-16T03:36:57.657777Z","shell.execute_reply":"2025-05-16T03:37:01.279144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataCol.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:01.280680Z","iopub.execute_input":"2025-05-16T03:37:01.281007Z","iopub.status.idle":"2025-05-16T03:37:03.018073Z","shell.execute_reply.started":"2025-05-16T03:37:01.280972Z","shell.execute_reply":"2025-05-16T03:37:03.017311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Group by 'activityID' and 'subject_id' to count rows for each combination\nactivity_subject_counts = dataCol.groupby(['activityID', 'subject_id']).size().reset_index(name='Count')\n\n# Set plot size for better readability\nplt.figure(figsize=(14, 8))\n\n# Create a bar plot with 'activityID' on the x-axis and 'Count' on the y-axis, colored by 'subject_id'\nsns.barplot(data=activity_subject_counts, x='activityID', y='Count', hue='subject_id', dodge=True, palette='viridis')\n\n# Customize plot appearance\nplt.title('Row Counts for Each Subject within Each Activity')\nplt.xlabel('Activity ID')\nplt.ylabel('Row Count')\nplt.legend(title='Subject ID', bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n# Display the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.018804Z","iopub.execute_input":"2025-05-16T03:37:03.019076Z","iopub.status.idle":"2025-05-16T03:37:03.867716Z","shell.execute_reply.started":"2025-05-16T03:37:03.019049Z","shell.execute_reply":"2025-05-16T03:37:03.866854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_activity_ids = dataCol['activityID'].unique()\nunique_subject_ids = dataCol['subject_id'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.868410Z","iopub.execute_input":"2025-05-16T03:37:03.868650Z","iopub.status.idle":"2025-05-16T03:37:03.891050Z","shell.execute_reply.started":"2025-05-16T03:37:03.868629Z","shell.execute_reply":"2025-05-16T03:37:03.890460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_activity_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.891867Z","iopub.execute_input":"2025-05-16T03:37:03.892218Z","iopub.status.idle":"2025-05-16T03:37:03.897597Z","shell.execute_reply.started":"2025-05-16T03:37:03.892186Z","shell.execute_reply":"2025-05-16T03:37:03.896952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_subject_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.898468Z","iopub.execute_input":"2025-05-16T03:37:03.898725Z","iopub.status.idle":"2025-05-16T03:37:03.913988Z","shell.execute_reply.started":"2025-05-16T03:37:03.898689Z","shell.execute_reply":"2025-05-16T03:37:03.913390Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_list = [ 1,  2,  3, 17, 16, 12, 13,  4,  7,  6,  5, 24]\nvalidation_list = [ 1,  2,  3, 17, 16, 12, 13,  4,  7,  6,  5, 24]\ntesting_list = [ 1,  2,  3, 17, 16, 12, 13,  4,  7,  6,  5, 24]\nall_list = all_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.914704Z","iopub.execute_input":"2025-05-16T03:37:03.914967Z","iopub.status.idle":"2025-05-16T03:37:03.929142Z","shell.execute_reply.started":"2025-05-16T03:37:03.914935Z","shell.execute_reply":"2025-05-16T03:37:03.928323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def imu_feature_extract(imu_type_data):\n    if imu_type_data.shape[0] < 3:  # Minimum required rows for np.gradient with edge_order=2\n        print_log(\"Not enough rows to calculate gradient. Skipping this file.\")\n        return pd.DataFrame()\n    imu_type_data[\"fft_x\"] = np.abs(np.fft.fft(imu_type_data[\"x\"].values))\n    imu_type_data[\"fft_y\"] = np.abs(np.fft.fft(imu_type_data[\"y\"].values))\n    imu_type_data[\"fft_z\"] = np.abs(np.fft.fft(imu_type_data[\"z\"].values))\n\n    imu_type_data[\"fd_x\"] = np.gradient(imu_type_data[\"x\"].values, edge_order=2)\n    imu_type_data[\"fd_y\"] = np.gradient(imu_type_data[\"y\"].values, edge_order=2)\n    imu_type_data[\"fd_z\"] = np.gradient(imu_type_data[\"z\"].values, edge_order=2)\n\n    imu_type_data[\"sd_x\"] = np.gradient(imu_type_data[\"fd_x\"].values, edge_order=2)\n    imu_type_data[\"sd_y\"] = np.gradient(imu_type_data[\"fd_y\"].values, edge_order=2)\n    imu_type_data[\"sd_z\"] = np.gradient(imu_type_data[\"fd_z\"].values, edge_order=2)\n\n    return imu_type_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.929931Z","iopub.execute_input":"2025-05-16T03:37:03.930175Z","iopub.status.idle":"2025-05-16T03:37:03.944686Z","shell.execute_reply.started":"2025-05-16T03:37:03.930155Z","shell.execute_reply":"2025-05-16T03:37:03.943830Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# When both hand and chest placements are considered - We need to add a logic here for every placement\nimu_prefixes = ['handAcc16', 'handGyro', 'handMagne','chestAcc16','chestGyro','chestMagne','ankleGyro','ankleAcc6','ankleMagne']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.945343Z","iopub.execute_input":"2025-05-16T03:37:03.945589Z","iopub.status.idle":"2025-05-16T03:37:03.962452Z","shell.execute_reply.started":"2025-05-16T03:37:03.945569Z","shell.execute_reply":"2025-05-16T03:37:03.961809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def apply_imu_feature_extraction(dataCol, imu_cols):\n    new_columns = []  \n\n    for col_prefix in imu_cols:\n\n        imu_data = dataCol[[f\"{col_prefix}_1\", f\"{col_prefix}_2\", f\"{col_prefix}_3\"]].copy()\n        imu_data.columns = ['x', 'y', 'z']\n        \n        extracted_features = imu_feature_extract(imu_data)\n        \n        new_cols = pd.DataFrame()\n        for feature in extracted_features.columns:\n            new_cols[f\"{col_prefix}_{feature}\"] = extracted_features[feature]\n\n        new_columns.append(new_cols)\n\n    dataCol = pd.concat([dataCol] + new_columns, axis=1)\n\n    for col_prefix in imu_cols:\n        dataCol.drop(columns=[f\"{col_prefix}_1\", f\"{col_prefix}_2\", f\"{col_prefix}_3\"], inplace=True)\n    \n    return dataCol\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.963205Z","iopub.execute_input":"2025-05-16T03:37:03.963395Z","iopub.status.idle":"2025-05-16T03:37:03.977273Z","shell.execute_reply.started":"2025-05-16T03:37:03.963378Z","shell.execute_reply":"2025-05-16T03:37:03.976660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def scaling(dataframe):\n    std_scaler = StandardScaler()\n    columns_names = list(dataframe.columns)\n    dataframe = std_scaler.fit_transform(dataframe.to_numpy())\n    dataframe = pd.DataFrame(dataframe, columns=columns_names)\n    return dataframe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.978078Z","iopub.execute_input":"2025-05-16T03:37:03.978377Z","iopub.status.idle":"2025-05-16T03:37:03.993220Z","shell.execute_reply.started":"2025-05-16T03:37:03.978348Z","shell.execute_reply":"2025-05-16T03:37:03.992613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_dir = './activity_data'\nactivity_counts = []\n\ntrain_dir = os.path.join('./', 'train')\ntest_dir = os.path.join('./', 'test')\nvalidation_dir = os.path.join('./', 'validation')\n\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)\nos.makedirs(validation_dir, exist_ok=True)\n\nfor activity_id in unique_activity_ids:\n    \n    activity_dir = os.path.join(base_dir, f'{activity_id}')\n    os.makedirs(activity_dir, exist_ok=True)\n    \n    \n    saved_csv_files = []\n    \n    \n    for subject_id in unique_subject_ids:\n        \n        df_activity_subject = dataCol[(dataCol['activityID'] == activity_id) & (dataCol['subject_id'] == subject_id)]\n        \n        \n        row_count = len(df_activity_subject)\n        \n        if row_count <=1:\n            \n            print_log(f'Skipped {subject_id} for activity {activity_id} due to insufficient data ({row_count} rows)')\n            continue\n        \n        \n        filename = os.path.join(activity_dir, f'{subject_id}.csv')\n        \n        \n        df_activity_subject.to_csv(filename, index=False)\n        \n        \n        activity_counts.append((activity_id, subject_id, row_count))\n        \n        \n        saved_csv_files.append(filename)\n        \n        print_log(f'Saved {filename}')\n    \n    \n    existing_csv_files = os.listdir(activity_dir)\n    current_csv_count = len(existing_csv_files)\n    print_log(existing_csv_files,\"existing_csv_files\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:03.993931Z","iopub.execute_input":"2025-05-16T03:37:03.994176Z","iopub.status.idle":"2025-05-16T03:37:43.282166Z","shell.execute_reply.started":"2025-05-16T03:37:03.994151Z","shell.execute_reply":"2025-05-16T03:37:43.281298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_sequences=[]\nvalidation_sequences=[]\ntest_sequences=[]\nactivity_list=all_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:43.283073Z","iopub.execute_input":"2025-05-16T03:37:43.283424Z","iopub.status.idle":"2025-05-16T03:37:43.288886Z","shell.execute_reply.started":"2025-05-16T03:37:43.283373Z","shell.execute_reply":"2025-05-16T03:37:43.287913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Configuration parameters\nbase_path = \"/kaggle/working/activity_data\"\nsequence_length = SEQUENCE_LENGTH   # Length of each IMU sequence\noverlap = OVERLAP  # Overlap between sequences\nactivity_list_train = []\nactivity_list_test = []\nactivity_list_val = []\n\n# Set specific users for testing\ntest_users = ['5.csv','6.csv']\nprint(f\"Selected users {test_users} as test users for all activities\")\n\n# Iterate through each activity\nfor activity_id in activity_list:\n    print(f\"Processing activity: {activity_id}\")\n    activity_dir = os.path.join(base_path, f'{activity_id}')\n\n    user_list_train = []\n    user_list_test = []\n    user_list_val = []\n\n    for user_id in os.listdir(activity_dir):\n        print(f\"Processing user: {user_id}\")\n        file_path = os.path.join(activity_dir, user_id)\n        imu_data = pd.read_csv(file_path)\n\n        # Apply IMU feature extraction and drop unnecessary columns\n        imu_data = apply_imu_feature_extraction(imu_data, imu_prefixes)\n        imu_data = imu_data.drop([\"subject_id\", \"activityID\"], axis=1)\n        imu_data = scaling(imu_data)\n\n        # Generate sequences\n        sequence_data = []\n        num_samples = len(imu_data)\n        num_sequences = (num_samples - sequence_length) // overlap + 1\n\n        for i in range(num_sequences):\n            sequence_start = i * overlap\n            sequence_end = sequence_start + sequence_length\n            if sequence_end <= num_samples:\n                sequence = imu_data.iloc[sequence_start:sequence_end].copy()\n                sequence_data.append(sequence.to_numpy())\n\n        # Split data according to LOSO-CV with specific test users\n        if user_id in test_users:\n            # Use all sequences from these users as test data\n            print(f\"if : {user_id}\")\n            user_list_test.append(sequence_data)\n        else:\n             # print(f\"else : {user_id}\")\n            # Split remaining users' data into train and validation sets\n            train_data, val_data = train_test_split(sequence_data, test_size=0.2, random_state=12345)\n              \n            user_list_train.append(train_data)\n            user_list_val.append(val_data)\n\n    # Append results to the main lists for each activity\n    activity_list_train.append(user_list_train)\n    activity_list_test.append(user_list_test)\n    activity_list_val.append(user_list_val)\n\n# Now, activity_list_train, activity_list_val, and activity_list_test contain the split data according to LOSO-CV","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:37:43.289811Z","iopub.execute_input":"2025-05-16T03:37:43.290026Z","iopub.status.idle":"2025-05-16T03:38:11.358616Z","shell.execute_reply.started":"2025-05-16T03:37:43.290006Z","shell.execute_reply":"2025-05-16T03:38:11.357703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_imu_data=activity_list_train\ntesting_imu_data=activity_list_test\nvalidation_imu_data=activity_list_val","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.359541Z","iopub.execute_input":"2025-05-16T03:38:11.359872Z","iopub.status.idle":"2025-05-16T03:38:11.364420Z","shell.execute_reply.started":"2025-05-16T03:38:11.359840Z","shell.execute_reply":"2025-05-16T03:38:11.363666Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# STDAT Model","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, k, d_model, seq_len):\n        super().__init__()\n        self.embedding = nn.Parameter(torch.zeros([k, d_model], dtype=torch.float), requires_grad=True)\n        nn.init.xavier_uniform_(self.embedding, gain=1)\n        self.positions = torch.tensor([i for i in range(seq_len)], requires_grad=False).unsqueeze(1).repeat(1, k)\n        s = 0.0\n        \n        interval = seq_len / k\n        mu = []\n        for _ in range(k):\n            mu.append(nn.Parameter(torch.tensor(s, dtype=torch.float), requires_grad=True))\n            s = s + interval\n        self.mu = nn.Parameter(torch.tensor(mu, dtype=torch.float).unsqueeze(0), requires_grad=True)\n        self.sigma = nn.Parameter(torch.tensor([torch.tensor([50.0], dtype=torch.float, requires_grad=True) for _ in range(k)]).unsqueeze(0))\n        \n    def normal_pdf(self, pos, mu, sigma):\n        a = pos - mu\n        log_p = -1*torch.mul(a, a)/(2*(sigma**2)) - torch.log(sigma)\n        return torch.nn.functional.softmax(log_p, dim=1)\n\n    def forward(self, inputs):\n        pdfs = self.normal_pdf(self.positions, self.mu, self.sigma)\n        pos_enc = torch.matmul(pdfs, self.embedding)\n        \n        return inputs + pos_enc.unsqueeze(0).repeat(inputs.size(0), 1, 1)\n\nclass TransformerEncoderLayer(nn.Module):\n    def __init__(self, d_model, heads, _heads, dropout, seq_len):\n        super(TransformerEncoderLayer, self).__init__()\n        \n        self.attention = nn.MultiheadAttention(d_model, heads, batch_first=True)\n        self._attention = nn.MultiheadAttention(seq_len, _heads, batch_first=True)\n        \n        self.attn_norm = nn.LayerNorm(d_model)\n        \n        self.cnn_units = 1\n        \n        self.cnn = nn.Sequential(\n            nn.Conv2d(1, self.cnn_units, (1, 1)),\n            nn.BatchNorm2d(self.cnn_units),\n            nn.Dropout(dropout),\n            nn.ReLU(),\n            nn.Conv2d(self.cnn_units, self.cnn_units, (3, 3), padding=1),\n            nn.BatchNorm2d(self.cnn_units),\n            nn.Dropout(dropout),\n            nn.ReLU(),\n            nn.Conv2d(self.cnn_units, 1, (5, 5), padding=2),\n            nn.BatchNorm2d(1),\n            nn.Dropout(dropout),\n            nn.ReLU()\n        )\n        \n        self.final_norm = nn.LayerNorm(d_model)\n\n    def forward(self, src, src_mask=None):\n        src = self.attn_norm(src + self.attention(src, src, src)[0] + self._attention(src.transpose(-1, -2), src.transpose(-1, -2), src.transpose(-1, -2))[0].transpose(-1, -2))\n        \n        src = self.final_norm(src + self.cnn(src.unsqueeze(dim=1)).squeeze(dim=1))\n        \n        return src\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, d_model, heads, _heads, seq_len, num_layer=2, dropout=0.1):\n        super(TransformerEncoder, self).__init__()\n\n        self.layers = nn.ModuleList()\n        for i in range(num_layer):\n            self.layers.append(TransformerEncoderLayer(d_model, heads, _heads, dropout, seq_len))\n\n    def forward(self, src):\n        for layer in self.layers:\n            src = layer(src)\n\n        return src\n\nclass Transformer(nn.Module):\n    def __init__(self, num_layer, d_model, k, heads, _heads, seq_len, trg_len, dropout):\n        super(Transformer, self).__init__()\n        \n\n        self.pos_encoding = PositionalEncoding(k, d_model, seq_len)\n\n        self.encoder = TransformerEncoder(d_model, heads, _heads, seq_len, num_layer, dropout)\n\n    def forward(self, inputs):\n        encoded_inputs = self.pos_encoding(inputs)\n\n        return self.encoder(encoded_inputs)\n\nclass Model(nn.Module):\n    def __init__(self, feature_count, l, trg_len, num_classes):\n        super(Model, self).__init__()\n        \n        \n        self.imu_transformer = Transformer(3, feature_count, 100, 4, 4, l, trg_len, 0.1)\n        \n        self.linear_imu = nn.Sequential(\n            nn.Linear(feature_count*l, (feature_count*l)//2),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear((feature_count*l)//2, trg_len),\n            nn.ReLU()\n        )\n        \n        # Batch normalization and dropout layers\n        self.batch_norm = nn.BatchNorm1d(trg_len)\n        self.dropout = nn.Dropout(0.5)\n        \n\n\n    def forward(self, inputs):\n        \n        embedding = self.linear_imu(torch.flatten(self.imu_transformer(inputs), start_dim=1, end_dim=2))\n        \n        # Apply batch normalization\n        embedding = self.batch_norm(embedding)\n        \n        # Apply dropout\n        embedding = self.dropout(embedding)\n        \n\n        \n        return embedding\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.365224Z","iopub.execute_input":"2025-05-16T03:38:11.365491Z","iopub.status.idle":"2025-05-16T03:38:11.382348Z","shell.execute_reply.started":"2025-05-16T03:38:11.365468Z","shell.execute_reply":"2025-05-16T03:38:11.381611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Attention Block","metadata":{}},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, input_dim):\n        super(Attention, self).__init__()\n        self.input_dim = input_dim\n        self.query = nn.Linear(input_dim, input_dim)\n        self.key = nn.Linear(input_dim, input_dim)\n        self.value = nn.Linear(input_dim, input_dim)\n        self.softmax = nn.Softmax(dim=2)\n        \n    def forward(self, x,y):\n        queries = self.query(x)\n        keys = self.key(y)\n        values = self.value(y)\n        queries_1=queries.unsqueeze(1)\n        keys_1=keys.unsqueeze(1)\n        values_1=values.unsqueeze(1)\n        scores = torch.bmm(queries_1, keys_1.transpose(1, 2)) / (self.input_dim ** 0.5)\n        \n        return scores, values_1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.383157Z","iopub.execute_input":"2025-05-16T03:38:11.383377Z","iopub.status.idle":"2025-05-16T03:38:11.402259Z","shell.execute_reply.started":"2025-05-16T03:38:11.383356Z","shell.execute_reply":"2025-05-16T03:38:11.401413Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cross-Sensor Attention","metadata":{}},{"cell_type":"code","source":"class CrossSensorAttention(nn.Module):\n    def __init__(self,input_dim,num_classes):\n        super(CrossSensorAttention,self).__init__()\n        self.input_dim=input_dim\n        self.softmax =nn.Softmax(dim=1)\n        self.attention_cal =Attention(input_dim)\n        self.classifier = nn.Linear(input_dim, num_classes)\n    \n    def forward(self,emb_1,emb_2,emb_3):\n        attention_weight_1_2,val_1_2 = self.attention_cal(emb_1,emb_2)\n        attention_weight_1_3,val_1_3 = self.attention_cal(emb_1,emb_3)\n        attention_weight_2_1,val_2_1 = self.attention_cal(emb_2,emb_1)\n        attention_weight_2_3,val_2_3 = self.attention_cal(emb_2,emb_3)\n        attention_weight_3_1,val_3_1 = self.attention_cal(emb_3,emb_1)\n        attention_weight_3_2,val_3_2 = self.attention_cal(emb_3,emb_2)\n        # print(attention_weight_1_2.shape,\"attention_weight_1_2\")\n        stacked_attention = torch.stack([attention_weight_1_2.squeeze(1),attention_weight_1_3.squeeze(1),attention_weight_2_1.squeeze(1),attention_weight_2_3.squeeze(1),attention_weight_3_1.squeeze(1),attention_weight_3_2.squeeze(1)],dim=1)\n        # print(stacked_attention.shape,\"stacked_attention\")\n        attention = self.softmax(stacked_attention)\n        # print(attention[32],\"att_val\")\n        # print(attention[0].sum(),\"att_sum\")\n        # print(attention.shape,\"attention\")\n        attention_matrix=attention.unsqueeze(2)\n        attention_matrix=attention_matrix.transpose(0,1)\n        # print(attention_matrix.shape,\"attention_matrix\")\n        attention_matrix_1=attention_matrix[0]\n        attention_matrix_2=attention_matrix[1]\n        attention_matrix_3=attention_matrix[2]\n        attention_matrix_4=attention_matrix[3]\n        attention_matrix_5=attention_matrix[4]\n        attention_matrix_6=attention_matrix[5]\n        attention_matrices = [attention_matrix_1, attention_matrix_2, attention_matrix_3, attention_matrix_4, attention_matrix_5, attention_matrix_6]\n        values = [val_1_2, val_1_3, val_2_1, val_2_3, val_3_1, val_3_2]\n        # print(attention_matrix_1.shape,\"attention_matrix_1\")\n        # print(val_1_2.shape,\"val_1_2\")\n        output_values = []\n        for attn, val in zip(attention_matrices, values):\n            out=torch.bmm(attn, val)\n            output_val=out.squeeze(dim=1)\n            output_values.append(output_val)\n        \n        final_embedding = emb_1+emb_2+emb_3\n        for val in output_values:\n            final_embedding+=val\n        class_scores =self.classifier(final_embedding)\n        \n        return class_scores,final_embedding,attention_matrix\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.402995Z","iopub.execute_input":"2025-05-16T03:38:11.403197Z","iopub.status.idle":"2025-05-16T03:38:11.417434Z","shell.execute_reply.started":"2025-05-16T03:38:11.403179Z","shell.execute_reply":"2025-05-16T03:38:11.416834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Overall Model","metadata":{}},{"cell_type":"code","source":"class MultiSensorModel(nn.Module):\n    def __init__(self, feature_count, l, trg_len, num_classes, feature_dim):\n        super(MultiSensorModel, self).__init__()\n        \n        # Three separate models for each sensor placement\n        self.sensor_model_1 = Model(feature_count, l, trg_len, num_classes)\n        # Cross-attention layer between embeddings\n        self.cross_sensor_attention = CrossSensorAttention(feature_dim, num_classes)\n\n    def forward(self, sensor_data1, sensor_data2,sensor_data3):\n        # Get embeddings from each sensor model\n        embedding_1 = self.sensor_model_1(sensor_data1)\n        embedding_2 = self.sensor_model_1(sensor_data2)\n        embedding_3 = self.sensor_model_1(sensor_data3)\n\n        class_scores, feature_embedding,attention_matrix = self.cross_sensor_attention(embedding_1, embedding_2,embedding_3)\n        \n        # Return class scores and feature embeddings\n        return class_scores, feature_embedding, embedding_1, embedding_2,embedding_3,attention_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.418117Z","iopub.execute_input":"2025-05-16T03:38:11.418340Z","iopub.status.idle":"2025-05-16T03:38:11.435859Z","shell.execute_reply.started":"2025-05-16T03:38:11.418321Z","shell.execute_reply":"2025-05-16T03:38:11.435165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GPU Specification","metadata":{}},{"cell_type":"code","source":"# torch.set_default_tensor_type('torch.cuda.FloatTensor')\nif torch.cuda.is_available():\n    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n    print_log(\"CUDA is available. Using GPU as default tensor type.\")\nelse:\n    torch.set_default_tensor_type('torch.FloatTensor')\n    print_log(\"CUDA not available. Using CPU as default tensor type.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.436564Z","iopub.execute_input":"2025-05-16T03:38:11.436761Z","iopub.status.idle":"2025-05-16T03:38:11.502361Z","shell.execute_reply.started":"2025-05-16T03:38:11.436744Z","shell.execute_reply":"2025-05-16T03:38:11.501414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size=BATCH_SIZE\n# epoch_batch_count=EPOCH_BATCH_COUNT\nimu_l=SEQUENCE_LENGTH # TODO This should be changed as hyperparameter\nimu_feature_count=IMU_FEATURE_COUNT\ntrg_len=512 # TODO This should be changed as hyperparameter\nclasses=CLASSES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.503419Z","iopub.execute_input":"2025-05-16T03:38:11.503754Z","iopub.status.idle":"2025-05-16T03:38:11.516340Z","shell.execute_reply.started":"2025-05-16T03:38:11.503723Z","shell.execute_reply":"2025-05-16T03:38:11.515521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_model_save_path = '/kaggle/working/best_models'\ncheckpoint_save_path = '/kaggle/working/checkpoints'\n\nsubprocess.run(f\"mkdir {best_model_save_path}\", shell=True)\nsubprocess.run(f\"mkdir {checkpoint_save_path}\", shell=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.517041Z","iopub.execute_input":"2025-05-16T03:38:11.517274Z","iopub.status.idle":"2025-05-16T03:38:11.541586Z","shell.execute_reply.started":"2025-05-16T03:38:11.517256Z","shell.execute_reply":"2025-05-16T03:38:11.540951Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train dataset","metadata":{}},{"cell_type":"code","source":"from math import floor, ceil\nclass TrainDataset(Dataset):\n    def __init__(self, training_data, batch_size):\n        self.training_data = training_data\n        self.batch_size = batch_size\n        flattened_length_train = sum(len(item) if isinstance(item, list) else 1 for sublist in training_data for item in (sublist if isinstance(sublist, list) else [sublist]))\n        self.epoch_batch_count = ceil(flattened_length_train / batch_size)\n        print(self.epoch_batch_count,\"epoch_batch_count\")\n\n    def __len__(self):\n        \n        return self.batch_size * self.epoch_batch_count\n        \n\n    def __getitem__(self, idx):\n        while True:\n            try:\n                genuine_user_idx = np.random.randint(0, len(self.training_data))\n                imposter_user_idx = np.random.randint(0, len(self.training_data))\n                # Ensure imposter_user_idx is different from genuine_user_idx\n                while imposter_user_idx == genuine_user_idx:\n                    imposter_user_idx = np.random.randint(0, len(self.training_data))\n                \n                # Validate the lengths of genuine_user and imposter_user data\n                if len(self.training_data[genuine_user_idx]) == 0 or len(self.training_data[imposter_user_idx]) == 0:\n                    raise ValueError(\"Empty user data detected.\")\n                \n                genuine_sess_1 = np.random.randint(0, len(self.training_data[genuine_user_idx]))\n                genuine_sess_2 = np.random.randint(0, len(self.training_data[genuine_user_idx]))\n                \n                # Ensure genuine_sess_2 is different from genuine_sess_1\n                while genuine_sess_2 == genuine_sess_1:\n                    genuine_sess_2 = np.random.randint(0, len(self.training_data[genuine_user_idx]))\n                \n                # Validate the lengths of genuine_sess_1 and genuine_sess_2 data\n                if len(self.training_data[genuine_user_idx][genuine_sess_1]) == 0 or len(self.training_data[genuine_user_idx][genuine_sess_2]) == 0:\n                    raise ValueError(\"Empty session data detected.\")\n                \n                imposter_sess = np.random.randint(0, len(self.training_data[imposter_user_idx]))\n                \n                # Validate the length of imposter_sess data\n                if len(self.training_data[imposter_user_idx][imposter_sess]) == 0:\n                    raise ValueError(\"Empty imposter session data detected.\")\n                \n                genuine_seq_1 = np.random.randint(0, len(self.training_data[genuine_user_idx][genuine_sess_1]))\n                genuine_seq_2 = np.random.randint(0, len(self.training_data[genuine_user_idx][genuine_sess_2]))\n                imposter_seq = np.random.randint(0, len(self.training_data[imposter_user_idx][imposter_sess]))\n#                 print(genuine_user_idx,genuine_sess_1,genuine_sess_2,imposter_user_idx,imposter_sess)\n                anchor = self.training_data[genuine_user_idx][genuine_sess_1][genuine_seq_1]\n                positive = self.training_data[genuine_user_idx][genuine_sess_2][genuine_seq_2]\n                negative = self.training_data[imposter_user_idx][imposter_sess][imposter_seq]\n\n\n                return anchor, positive, negative, genuine_user_idx, imposter_user_idx\n            \n            except ValueError as e:\n                print_log(f\"Encountered ValueError: {str(e)}. Retrying with new indices.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.542325Z","iopub.execute_input":"2025-05-16T03:38:11.542551Z","iopub.status.idle":"2025-05-16T03:38:11.552663Z","shell.execute_reply.started":"2025-05-16T03:38:11.542503Z","shell.execute_reply":"2025-05-16T03:38:11.551915Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test dataset","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, eval_data):\n        self.eval_data = eval_data\n        self.num_sessions = [len(user_sessions) for user_sessions in self.eval_data]  # List of number of sessions for each user\n        self.num_seqs = [len(session) for user_sessions in self.eval_data for session in user_sessions]  # Total sequences across all users\n\n    def __len__(self):\n        # Total length of dataset will be the sum of all sequences across all users and sessions\n        return sum(len(self.eval_data[user_idx][session_idx]) for user_idx in range(len(self.eval_data))\n                   for session_idx in range(len(self.eval_data[user_idx])))\n\n    def __getitem__(self, idx):\n        # Find the user index and session index dynamically\n        cumulative_length = 0\n        for user_idx in range(len(self.eval_data)):\n            for session_idx in range(len(self.eval_data[user_idx])):\n                session_length = len(self.eval_data[user_idx][session_idx])\n                if cumulative_length + session_length > idx:\n                    seq_idx = idx - cumulative_length\n                    data = self.eval_data[user_idx][session_idx][seq_idx]\n\n                    # Debugging statements\n                    debug_log(f\"Index: {idx}, User Index: {user_idx}, Session Index: {session_idx}, Sequence Index: {seq_idx}\")\n\n                    # Check if data is None\n                    if data is None:\n                        error_log(f\"Returned data is None for index: {idx} in testdata\")\n                    return data, user_idx\n\n                cumulative_length += session_length\n        \n        # If we get here, idx is out of bounds\n        raise IndexError(\"Index out of bounds for dataset.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.553455Z","iopub.execute_input":"2025-05-16T03:38:11.553743Z","iopub.status.idle":"2025-05-16T03:38:11.570320Z","shell.execute_reply.started":"2025-05-16T03:38:11.553713Z","shell.execute_reply":"2025-05-16T03:38:11.569732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testing_data=testing_imu_data\ntest_dataset = TestDataset(testing_data)\ntest_dataloader = DataLoader(test_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.570988Z","iopub.execute_input":"2025-05-16T03:38:11.571206Z","iopub.status.idle":"2025-05-16T03:38:11.587683Z","shell.execute_reply.started":"2025-05-16T03:38:11.571188Z","shell.execute_reply":"2025-05-16T03:38:11.587046Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loss Function - Triplet Loss","metadata":{}},{"cell_type":"code","source":"class TripletLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n        \n    def calc_euclidean(self, x1, x2):\n        return (x1 - x2).pow(2).sum(dim=1).sqrt()\n    \n    def calc_cosine(self, x1, x2):\n        dot_product_sum = (x1*x2).sum(dim=1)\n        norm_multiply = (x1.pow(2).sum(dim=1).sqrt()) * (x2.pow(2).sum(dim=1).sqrt())\n        return dot_product_sum / norm_multiply\n    \n    def calc_manhattan(self, x1, x2):\n        return (x1-x2).abs().sum(dim=1)\n    \n    def forward(self, anchor, positive, negative):\n        distance_positive = self.calc_euclidean(anchor, positive)\n        distance_negative = self.calc_euclidean(anchor, negative)\n        losses = torch.relu(distance_positive - distance_negative + self.margin)\n\n        return losses.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.593252Z","iopub.execute_input":"2025-05-16T03:38:11.593445Z","iopub.status.idle":"2025-05-16T03:38:11.602903Z","shell.execute_reply.started":"2025-05-16T03:38:11.593428Z","shell.execute_reply":"2025-05-16T03:38:11.602155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = TrainDataset(training_imu_data, batch_size)\ndataloader = DataLoader(dataset, batch_size=batch_size)\nmodel = MultiSensorModel(36, imu_l, trg_len, CLASSES, trg_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.604638Z","iopub.execute_input":"2025-05-16T03:38:11.604840Z","iopub.status.idle":"2025-05-16T03:38:11.916948Z","shell.execute_reply.started":"2025-05-16T03:38:11.604821Z","shell.execute_reply":"2025-05-16T03:38:11.916084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_fn = TripletLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE,weight_decay=1e-4) # change the learning rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:11.917865Z","iopub.execute_input":"2025-05-16T03:38:11.918176Z","iopub.status.idle":"2025-05-16T03:38:13.906145Z","shell.execute_reply.started":"2025-05-16T03:38:11.918145Z","shell.execute_reply":"2025-05-16T03:38:13.905290Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Scheduler on LR based on validation loss","metadata":{}},{"cell_type":"code","source":"# Custom Scheduler Class\nclass CustomLRScheduler:\n    def __init__(self, optimizer, patience=5, factor=0.3, min_lr=1e-4):\n        \"\"\"\n        Parameters:\n        - optimizer: PyTorch optimizer\n        - patience: Number of epochs to wait for validation loss improvement\n        - factor: Multiplicative factor to reduce the LR\n        - min_lr: Minimum learning rate allowed\n        \"\"\"\n        self.optimizer = optimizer\n        self.patience = patience\n        self.factor = factor\n        self.min_lr = min_lr\n        self.best_loss = float('inf')\n        self.wait = 0\n\n    def step(self, val_loss):\n        \"\"\"\n        Checks the validation loss and adjusts the LR if needed.\n        Parameters:\n        - val_loss: Validation loss of the current epoch\n        \"\"\"\n        if val_loss < self.best_loss:\n            self.best_loss = val_loss\n            self.wait = 0  # Reset the wait counter\n        else:\n            self.wait += 1\n            if self.wait >= self.patience:\n                # Reduce LR if no improvement for 'patience' epochs\n                self._reduce_lr()\n                self.wait = 0  # Reset the wait counter\n\n    def _reduce_lr(self):\n        print_log(\"No improvement in the validation loss\")\n        for param_group in self.optimizer.param_groups:\n            old_lr = param_group['lr']\n            new_lr = max(old_lr * self.factor, self.min_lr)  # Ensure LR doesn't go below min_lr\n            if old_lr > self.min_lr:\n                param_group['lr'] = new_lr\n                print(f\"Reducing learning rate from {old_lr:.6f} to {new_lr:.6f}\")\n            else:\n                print(f\"Learning rate is already at the minimum value {self.min_lr:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:13.906966Z","iopub.execute_input":"2025-05-16T03:38:13.907577Z","iopub.status.idle":"2025-05-16T03:38:13.914344Z","shell.execute_reply.started":"2025-05-16T03:38:13.907553Z","shell.execute_reply":"2025-05-16T03:38:13.913305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize the scheduler\nscheduler = CustomLRScheduler(optimizer, patience=PATIENCE, factor=LR_FACTOR, min_lr= MIN_LR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:13.915127Z","iopub.execute_input":"2025-05-16T03:38:13.915399Z","iopub.status.idle":"2025-05-16T03:38:13.935186Z","shell.execute_reply.started":"2025-05-16T03:38:13.915368Z","shell.execute_reply":"2025-05-16T03:38:13.934559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"g_eer = math.inf\ninit_epoch = 0\nepochs=EPOCHS ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:13.935831Z","iopub.execute_input":"2025-05-16T03:38:13.936069Z","iopub.status.idle":"2025-05-16T03:38:13.949310Z","shell.execute_reply.started":"2025-05-16T03:38:13.936049Z","shell.execute_reply":"2025-05-16T03:38:13.948450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_accuracy = BEST_ACCURACY\nbest_loss = BEST_LOSS\ntraining_losses = []\nvalidation_losses = []\noverall_losses =[]\nfeature_embeddings_train=[]\nsaved_models = []\nmax_saved_models = MAX_SAVED_MODELS  \nfeature_length=36\nlr_history = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:13.950116Z","iopub.execute_input":"2025-05-16T03:38:13.950395Z","iopub.status.idle":"2025-05-16T03:38:13.964153Z","shell.execute_reply.started":"2025-05-16T03:38:13.950367Z","shell.execute_reply":"2025-05-16T03:38:13.963563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_worst_loss_and_acc_in_existing_model(saved_models):\n    worst_loss = float('-inf')\n    worst_accuracy = float('inf')\n    for model_info in saved_models:\n        loss = model_info['loss']\n        accuracy = model_info['accuracy']\n        if worst_loss <  loss:\n            worst_loss = loss\n        if worst_accuracy > accuracy:\n            worst_accuracy = accuracy\n    return  worst_loss, worst_accuracy\n\ndef memory_is_low():\n    \"\"\"Check if memory is low. You can implement your own logic here.\"\"\"\n    # Placeholder logic; replace with actual memory checking\n    import psutil\n    return psutil.virtual_memory().available < (100 * 1024 * 1024)  # Less than 100 MB\n\ndef find_worst_model_by_accuracy(saved_models):\n    worst_model = None\n    worst_accuracy = float('inf')\n    for model_info in saved_models:\n        if model_info['accuracy'] < worst_accuracy:\n            worst_accuracy = model_info['accuracy']\n            worst_model = model_info\n    if worst_model:\n        print_log(f\"Worst model - Path: {worst_model['path']}, Accuracy: {worst_model['accuracy']:.6f}, Loss: {worst_model['loss']:.6f}\")\n    if worst_model:\n        if os.path.exists(worst_model['path']):\n            os.remove(worst_model['path'])\n            print_log(f\"Deleted worst model by less accuracy: {worst_model['path']} with Accuracy: {worst_model['accuracy']:.6f}, Loss: {worst_model['loss']:.6f}\")\n        saved_models.remove(worst_model)\n\ndef find_worst_model_by_loss(saved_models):\n    worst_model = None\n    worst_loss = float('-inf')\n    for model_info in saved_models:\n        if model_info['loss'] > worst_loss:\n            worst_loss = model_info['loss']\n            worst_model = model_info\n    if worst_model:\n        print_log(f\"Worst model - Path: {worst_model['path']}, Accuracy: {worst_model['accuracy']:.6f}, Loss: {worst_model['loss']:.6f}\")\n    if worst_model:\n        if os.path.exists(worst_model['path']):\n            os.remove(worst_model['path'])\n            print_log(f\"Deleted worst model by higher loss: {worst_model['path']} with Accuracy: {worst_model['accuracy']:.6f}, Loss: {worst_model['loss']:.6f}\")\n        saved_models.remove(worst_model)\n\ndef find_worst_model_by_combined_metric(saved_models, weight_loss=0.5, weight_accuracy=0.5):\n    worst_model = None\n    worst_combined_metric = float('inf')\n    combined_matrix_values = []\n    max_loss = 100\n    min_loss = 0\n    max_accuracy = 100\n    min_accuracy = 0\n    for model_info in saved_models:\n        normalized_loss = (model_info['loss'] - min_loss) / (max_loss - min_loss)\n        normalized_accuracy = (model_info['accuracy'] - min_accuracy) / (max_accuracy - min_accuracy)\n        # find combined metric, We want high accuracy and less losses\n        combined_metric = (weight_accuracy * normalized_accuracy) -(weight_loss * normalized_loss)\n        combined_matrix_values.append(combined_metric)\n        model_info[\"combined_metric\"] = combined_metric\n        \n        # Find the model with the smallest combined metric\n        if combined_metric < worst_combined_metric:\n            worst_combined_metric = combined_metric\n            worst_model = model_info\n    if worst_model:\n        print_log(f\"Worst model : Path: {worst_model['path']}, Accuracy: {worst_model['accuracy']:.6f}, Loss: {worst_model['loss']:.6f}\")\n        print_log(f\"Because this is have minimum combined matrix = {worst_combined_metric}, All combined matric {combined_matrix_values}\")\n    if worst_model:\n        if os.path.exists(worst_model['path']):\n            os.remove(worst_model['path'])\n            print_log(f\"Deleted worst model by less accuracy and higher loss: {worst_model['path']} with Accuracy: {worst_model['accuracy']:.6f}, Loss: {worst_model['loss']:.6f}\")\n        saved_models.remove(worst_model)\n\ntotal_losses = []\ntotal_accuracy = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:13.964781Z","iopub.execute_input":"2025-05-16T03:38:13.965033Z","iopub.status.idle":"2025-05-16T03:38:14.168128Z","shell.execute_reply.started":"2025-05-16T03:38:13.965012Z","shell.execute_reply":"2025-05-16T03:38:14.166797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming `training_imu_data` is a nested list\nflattened_length_train = sum(len(item) if isinstance(item, list) else 1 for sublist in training_imu_data for item in (sublist if isinstance(sublist, list) else [sublist]))\nprint(\"Length of flattened list:\", flattened_length_train)\n\nflattened_length_test = sum(len(item) if isinstance(item, list) else 1 for sublist in testing_imu_data for item in (sublist if isinstance(sublist, list) else [sublist]))\nprint(\"Length of flattened list:\", flattened_length_test)\n\nflattened_length_val = sum(len(item) if isinstance(item, list) else 1 for sublist in validation_imu_data for item in (sublist if isinstance(sublist, list) else [sublist]))\nprint(\"Length of flattened list:\", flattened_length_val)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:14.169010Z","iopub.execute_input":"2025-05-16T03:38:14.169310Z","iopub.status.idle":"2025-05-16T03:38:14.195431Z","shell.execute_reply.started":"2025-05-16T03:38:14.169280Z","shell.execute_reply":"2025-05-16T03:38:14.194762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"for i in range(init_epoch, epochs):\n    model_saved = 0\n    print_log(f\"Epoch - {i+1} is started\")\n\n    t_loss = 0.0\n    o_loss =0.0\n    correct_predictions = 0\n    total_predictions = 0\n    \n    start = time.time()\n    model.train(True)\n    \n    # Training phase\n    for batch_idx, item in enumerate(dataloader):\n        anchor, positive, negative, anchor_class,negative_class = item\n        optimizer.zero_grad()\n        # Forward pass for triplet loss\n#         class_scores,concatenated_embedding,embedding_1, embedding_2\n        anchor_class_scores,anchor_features,anch_emb1,anch_emb2,anch_emb3,attention_matrix_anch= model(anchor.float()[:, :, :feature_length],anchor.float()[:, :, feature_length:2*feature_length],anchor.float()[:, :, 2*feature_length:])\n        positive_class_scores,positive_features,posi_emb1,posi_emb2,posi_emb3,attention_matrix_posi = model(positive.float()[:, :, :feature_length],positive.float()[:, :, feature_length:2*feature_length],positive.float()[:, :, 2*feature_length:])\n        negative_class_scores,negative_features,nega_emb1,nega_emb2,nega_emb3,attention_matrix_nega = model(negative.float()[:, :, :feature_length],negative.float()[:, :, feature_length:2*feature_length],negative.float()[:, :, 2*feature_length:])\n\n        triplet_loss_place_1 = loss_fn(anch_emb1,posi_emb1,nega_emb1)\n        triplet_loss_place_2 = loss_fn(anch_emb2,posi_emb2,nega_emb2)\n        triplet_loss_place_3 = loss_fn(anch_emb3,posi_emb3,nega_emb3)\n        triplet_loss_tot = triplet_loss_place_1+triplet_loss_place_2+ triplet_loss_place_3\n        # overall_loss =loss_fn(anchor_features,positive_features,negative_features)\n        # print(triplet_loss_tot,overall_loss)\n        # Forward pass for classification loss\n\n        all_class_scores = torch.cat([anchor_class_scores, positive_class_scores, negative_class_scores], dim=0)\n        all_labels_train = torch.cat([anchor_class, anchor_class, negative_class], dim=0)  # Assuming the third element is the label\n        class_loss = nn.CrossEntropyLoss()(all_class_scores, all_labels_train)\n\n        total_loss =  class_loss + (0.1* triplet_loss_tot/3)\n        # total_loss= triplet_loss_tot\n\n        total_loss.backward()\n        optimizer.step()\n#         optimizer.zero_grad()\n        \n        t_loss += total_loss.item()\n        \n        _, predicted_labels = torch.max(all_class_scores, dim=1)\n        correct_predictions += (predicted_labels == all_labels_train).sum().item()\n        total_predictions += all_labels_train.size(0)\n        # o_loss += overall_loss.item()\n        \n    \n    t_loss /= len(dataloader)\n    # o_loss /= len(dataloader)\n    training_losses.append(t_loss)\n    training_accuracy = correct_predictions / total_predictions * 100\n    print_log(f\"Epoch {i+1}: Training Loss = {t_loss:.4f}, Training Accuracy = {training_accuracy:.2f}%\")\n    # overall_losses.append(o_loss)\n    \n\n\n    \n    # Validation phase\n    model.eval()\n    v_loss = 0.0\n    all_preds = []\n    all_labels = []\n    t_dataset = TestDataset(validation_imu_data)\n    \n    t_dataloader = DataLoader(t_dataset, batch_size=batch_size, shuffle=False)\n    tot = 0\n    print_log(f\"The lenth of t_dataloader : {len(t_dataloader)}\")\n    for batch_idx_t, item_t in enumerate(t_dataloader):\n        with torch.no_grad():\n            val = tot // 992\n            tot += 1\n            \n            item_t_in,class_label=item_t\n            item_out = model(item_t_in.float()[:, :, :feature_length],item_t_in.float()[:, :, feature_length:feature_length*2],item_t_in.float()[:,:,feature_length*2:])\n            class_scores = item_out[0]\n            attention_matrix_val=item_out[5]\n            true_labels = class_label\n            predicted_classes = torch.argmax(class_scores, dim=1)\n            # if true_labels!=predicted_classes:\n            # print(true_labels,predicted_classes)\n            correct_predictions = (predicted_classes == true_labels)\n            \n            accuracy = correct_predictions.sum().item() / len(true_labels)\n            \n            class_loss_val = nn.CrossEntropyLoss()(class_scores, true_labels)\n            v_loss += class_loss_val.item()\n            all_preds.extend(predicted_classes.tolist())\n            all_labels.extend(true_labels.tolist())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    precision = precision_score(all_labels, all_preds, average='macro')\n    recall = recall_score(all_labels, all_preds, average='macro')\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    v_loss /= len(t_dataloader)\n    \n    print_log(f\"loop done  {tot}\")\n    # Step the scheduler based on the validation loss\n    scheduler.step(v_loss)\n    curr_lr = optimizer.param_groups[0]['lr']\n    print(f\"Epoch {i+1}/{epochs}, Validation Loss: {v_loss:.6f}, Current LR: {curr_lr:.6f}\")\n    wandb.log({\"accuracy\": accuracy, \"loss\": t_loss, \"precision\": precision, \"recall\": recall, \"v_loss\":v_loss, 'f1':f1, 'lr' : curr_lr,\"training_accuracy\":training_accuracy})\n    # wandb.log({\"accuracy\": accuracy, \"loss\": t_loss, \"precision\": precision, \"recall\": recall, \"v_loss\":v_loss, 'f1':f1})\n    end = time.time()\n    \n    total_losses.append(t_loss)\n    validation_losses.append(v_loss)\n    total_accuracy.append(accuracy)\n    lr_history.append(curr_lr)\n    \n    print_log(f\"------> Epoch No: {i+1} => Loss: {t_loss:.6f} >> Accuracy: {accuracy:.6f} >> Precision: {precision:.6f} >> Recall: {recall:.6f} >> F1: {f1:.6f} >> Time: {end-start:.2f}\")\n    \n    # Check memory status\n    if memory_is_low():\n        print_log(f\"Memory is running low, attempting to free up space by deleting the worst model.\")\n        # find_worst_model_by_loss(saved_models)\n        find_worst_model_by_accuracy(saved_models)\n        # find_worst_model_by_combined_metric(saved_models)\n        # assign last best loss and accuracy in existing models\n        if len(saved_models) > max_saved_models:\n            best_loss, best_accuracy = find_worst_loss_and_acc_in_existing_model(saved_models)\n\n    # Save model if validation loss improves and This model not saved before\n    if t_loss < best_loss:\n        print_log(f\"Loss improved from {best_loss:.6f} to {t_loss:.6f}. \")\n        if model_saved:\n            print_log(\"Already model saved. Skip this model by loss.\")\n        else:\n            print_log(\"Saving model.................\")\n            model_path = f\"{best_model_save_path}/epoch_{i+1}_accuracy_{accuracy:.6f}_loss_{t_loss:.6f}.pt\"\n            torch.save(model, model_path)\n            print_log(f\"Best model saved at (by loss): {model_path}\")\n            saved_models.append({'path': model_path, 'loss': t_loss, 'accuracy' : accuracy})\n            # Model saved\n            model_saved = 1\n    \n            if len(saved_models) > max_saved_models:\n                # find_worst_model_by_loss(saved_models)\n                find_worst_model_by_accuracy(saved_models)\n                # find_worst_model_by_combined_metric(saved_models)\n            \n                # assign last best loss and accuracy in existing models\n                best_loss, best_accuracy = find_worst_loss_and_acc_in_existing_model(saved_models)\n\n\n    # Save model if validation accuracy improves\n    if accuracy > best_accuracy :\n        print_log(f\"Accuracy improved from {best_accuracy:.6f} to {accuracy:.6f}.\")\n        if model_saved:\n            print_log(\"But, Already model saved. Skip this model by accuracy.\")\n        else:\n            print_log(\"Saving model.................\")\n            model_path = f\"{best_model_save_path}/epoch_{i+1}_accuracy_{accuracy:.6f}_loss_{t_loss:.6f}.pt\"\n            torch.save(model, model_path)\n            print_log(f\"Best model saved at (by accuracy): {model_path}\")\n            saved_models.append({'path': model_path, 'loss' : t_loss, 'accuracy': accuracy})\n            # Model saved\n            model_saved = 1\n    \n            if len(saved_models) > max_saved_models:\n                # find_worst_model_by_loss(saved_models)\n                find_worst_model_by_accuracy(saved_models)\n#                 find_worst_model_by_combined_metric(saved_models)\n            \n                # assign last best loss and accuracy in existing models\n                best_loss, best_accuracy = find_worst_loss_and_acc_in_existing_model(saved_models)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:38:14.196272Z","iopub.execute_input":"2025-05-16T03:38:14.196554Z","iopub.status.idle":"2025-05-16T03:40:51.982643Z","shell.execute_reply.started":"2025-05-16T03:38:14.196523Z","shell.execute_reply":"2025-05-16T03:40:51.981793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"attention_matrix_val.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:51.983610Z","iopub.execute_input":"2025-05-16T03:40:51.983920Z","iopub.status.idle":"2025-05-16T03:40:51.989768Z","shell.execute_reply.started":"2025-05-16T03:40:51.983886Z","shell.execute_reply":"2025-05-16T03:40:51.988991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"attention_matrix_val=attention_matrix_val.transpose(0,1)\nattention_matrix_val=attention_matrix_val.squeeze(dim=2)\nattention_matrix_val=attention_matrix_val.squeeze(dim=2)\nattention_matrix_val.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:51.990467Z","iopub.execute_input":"2025-05-16T03:40:51.990696Z","iopub.status.idle":"2025-05-16T03:40:52.007209Z","shell.execute_reply.started":"2025-05-16T03:40:51.990670Z","shell.execute_reply":"2025-05-16T03:40:52.006395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"attention_matrix_val","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:52.007977Z","iopub.execute_input":"2025-05-16T03:40:52.008240Z","iopub.status.idle":"2025-05-16T03:40:52.189232Z","shell.execute_reply.started":"2025-05-16T03:40:52.008207Z","shell.execute_reply":"2025-05-16T03:40:52.188543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"attention_matrix_val.sum(dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:52.190005Z","iopub.execute_input":"2025-05-16T03:40:52.190237Z","iopub.status.idle":"2025-05-16T03:40:52.197776Z","shell.execute_reply.started":"2025-05-16T03:40:52.190215Z","shell.execute_reply":"2025-05-16T03:40:52.197164Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot loss","metadata":{}},{"cell_type":"code","source":"# Plotting training and validation loss\nplt.figure(figsize=(10, 5))\nplt.plot(training_losses, label='Training Loss')\nplt.plot(validation_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training Loss Over Epochs')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:52.198545Z","iopub.execute_input":"2025-05-16T03:40:52.198825Z","iopub.status.idle":"2025-05-16T03:40:52.368669Z","shell.execute_reply.started":"2025-05-16T03:40:52.198799Z","shell.execute_reply":"2025-05-16T03:40:52.367782Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot learning rate","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(range(1, epochs + 1), lr_history, marker='o', label=\"Learning Rate\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Learning Rate\")\nplt.title(\"Epochs vs. Learning Rate\")\nplt.grid(True)\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:52.369529Z","iopub.execute_input":"2025-05-16T03:40:52.369810Z","iopub.status.idle":"2025-05-16T03:40:52.542030Z","shell.execute_reply.started":"2025-05-16T03:40:52.369776Z","shell.execute_reply":"2025-05-16T03:40:52.541255Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, eval_data):\n        self.eval_data = eval_data\n        \n        # Precompute the flattened index map\n        self.index_map = []  # List to store (user_idx, session_idx, seq_idx)\n        for user_idx, user_sessions in enumerate(eval_data):\n            for session_idx, session_sequences in enumerate(user_sessions):\n                for seq_idx in range(len(session_sequences)):\n                    self.index_map.append((user_idx, session_idx, seq_idx))\n\n    def __len__(self):\n        # Total number of data points is the size of the index map\n        return len(self.index_map)\n\n    def __getitem__(self, idx):\n        # Retrieve the hierarchical indices from the map\n        user_idx, session_idx, seq_idx = self.index_map[idx]\n        return self.eval_data[user_idx][session_idx][seq_idx],user_idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:52.542754Z","iopub.execute_input":"2025-05-16T03:40:52.542966Z","iopub.status.idle":"2025-05-16T03:40:52.548700Z","shell.execute_reply.started":"2025-05-16T03:40:52.542946Z","shell.execute_reply":"2025-05-16T03:40:52.547853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testing_data=testing_imu_data\ntest_dataset = TestDataset(testing_data)\ntest_dataloader = DataLoader(test_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:52.549624Z","iopub.execute_input":"2025-05-16T03:40:52.549955Z","iopub.status.idle":"2025-05-16T03:40:52.571672Z","shell.execute_reply.started":"2025-05-16T03:40:52.549924Z","shell.execute_reply":"2025-05-16T03:40:52.571029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get a list of files in the BEST_MODEL_PATH directory\nBEST_MODEL_PATH='/kaggle/working/best_models/'\nexisting_models = os.listdir(BEST_MODEL_PATH)\nbest_accuracy_test=0\nbest_precision_test=0\nbest_recall_test=0\nbest_f1_test=0\n\n# Loop through the files in the directory\nfor model_file in existing_models:\n    feature_embeddings = []\n    all_preds_test = []\n    all_labels_test = []\n    # Full path of the model\n    model_path = os.path.join(BEST_MODEL_PATH, model_file)\n\n    # Check if it's a file (and not a directory)\n    if os.path.isfile(model_path):\n        print(f\"Processing model: {model_file}\")\n        test_model = torch.load(model_path)\n        test_model.eval()\n        test_model.train(False)\n        for batch_idx_t, item_t in enumerate(test_dataloader):\n            with torch.no_grad():\n        \n                item_t_in,class_label=item_t\n        \n                true_labels=class_label\n        \n                item_out = test_model(item_t_in.float()[:, :, :feature_length],item_t_in.float()[:, :, feature_length:feature_length*2],item_t_in.float()[:, :, 2*feature_length:])\n                class_scores=item_out[0]\n                feature_embeddings.append(item_out[1])\n                predicted_classes = torch.argmax(class_scores, dim=1)\n                all_preds_test.extend(predicted_classes.tolist())\n                all_labels_test.extend(true_labels.tolist())\n        accuracy_test = accuracy_score(all_labels_test, all_preds_test)\n        precision_test = precision_score(all_labels_test, all_preds_test, average='macro')\n        recall_test = recall_score(all_labels_test, all_preds_test, average='macro')\n        f1_test = f1_score(all_labels_test, all_preds_test, average='macro')\n        \n        \n        print_log(f\"Accuracy: {accuracy_test:.6f} - Precision: {precision_test:.6f} - Recall: {recall_test:.6f} - F1: {f1_test:.6f}\")\n        if accuracy_test>best_accuracy_test:\n            final_best_model=model_path\n        best_accuracy_test = max(best_accuracy_test, accuracy_test)\n        best_precision_test =max(best_precision_test,precision_test)\n        best_recall_test =max(best_recall_test,recall_test)\n        best_f1_test=max(best_f1_test,f1_test)\n        \nwandb.log({\"Test Accuracy\": best_accuracy_test, \"Test Precision\": best_precision_test, \"Test Recall\": best_recall_test, 'Test f1':best_f1_test})\nprint_log(final_best_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:40:52.572432Z","iopub.execute_input":"2025-05-16T03:40:52.572684Z","iopub.status.idle":"2025-05-16T03:41:37.529157Z","shell.execute_reply.started":"2025-05-16T03:40:52.572664Z","shell.execute_reply":"2025-05-16T03:41:37.528371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_embeddings = []\nall_preds_test = []\nall_labels_test = []\ntest_model = torch.load(final_best_model)\ntest_model.eval()\ntest_model.train(False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:41:37.529875Z","iopub.execute_input":"2025-05-16T03:41:37.530071Z","iopub.status.idle":"2025-05-16T03:41:37.603959Z","shell.execute_reply.started":"2025-05-16T03:41:37.530052Z","shell.execute_reply":"2025-05-16T03:41:37.603303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfeature_embeddings = []\ntot=0\nall_preds_test = []\nall_labels_test = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:41:37.604806Z","iopub.execute_input":"2025-05-16T03:41:37.605144Z","iopub.status.idle":"2025-05-16T03:41:37.609697Z","shell.execute_reply.started":"2025-05-16T03:41:37.605088Z","shell.execute_reply":"2025-05-16T03:41:37.608901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfor batch_idx_t, item_t in enumerate(test_dataloader):\n    with torch.no_grad():\n\n        item_t_in,class_label=item_t\n\n        true_labels=class_label\n\n        item_out = test_model(item_t_in.float()[:, :, :feature_length],item_t_in.float()[:, :, feature_length:feature_length*2],item_t_in.float()[:, :, 2*feature_length:])\n        class_scores=item_out[0]\n        feature_embeddings.append(item_out[1])\n        predicted_classes = torch.argmax(class_scores, dim=1)\n        all_preds_test.extend(predicted_classes.tolist())\n        all_labels_test.extend(true_labels.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:41:37.610405Z","iopub.execute_input":"2025-05-16T03:41:37.610700Z","iopub.status.idle":"2025-05-16T03:41:59.911826Z","shell.execute_reply.started":"2025-05-16T03:41:37.610670Z","shell.execute_reply":"2025-05-16T03:41:59.911180Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy_test = accuracy_score(all_labels_test, all_preds_test)\nprecision_test = precision_score(all_labels_test, all_preds_test, average='macro')\nrecall_test = recall_score(all_labels_test, all_preds_test, average='macro')\nf1_test = f1_score(all_labels_test, all_preds_test, average='macro')\n\nprint_log(f\"Accuracy: {accuracy_test:.6f} - Precision: {precision_test:.6f} - Recall: {recall_test:.6f} - F1: {f1_test:.6f}\")\nwandb.log({\"Test Accuracy\": accuracy_test, \"Test Precision\": precision_test, \"Test Recall\": recall_test, 'Test f1':f1_test})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:41:59.912509Z","iopub.execute_input":"2025-05-16T03:41:59.912708Z","iopub.status.idle":"2025-05-16T03:41:59.960316Z","shell.execute_reply.started":"2025-05-16T03:41:59.912690Z","shell.execute_reply":"2025-05-16T03:41:59.959502Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training Accuracy","metadata":{}},{"cell_type":"code","source":"conf_matrix = confusion_matrix(all_labels, all_preds)\n\n# Calculate the accuracy for each class\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n\n# Print the accuracy for each class\nfor i, class_accuracy in enumerate(class_accuracies):\n    print_log(f\"Accuracy for class {i}: {class_accuracy:.6f}\")\n\n\nplt.figure(figsize=(10, 7))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nimage_path = 'confusion_matrix.png'\nplt.savefig(image_path)\nwandb.log({\n    \"confusion_matrix\": wandb.Image(image_path)  # Log the t-SNE plot image\n})\nplt.show()\nprint_log(\"Confusion matrix is create sucessfully using test\")\nwandb.log({\"confusion_matrix_test\": wandb.Image('confusion_matrix.png')})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:41:59.961256Z","iopub.execute_input":"2025-05-16T03:41:59.961478Z","iopub.status.idle":"2025-05-16T03:42:01.115320Z","shell.execute_reply.started":"2025-05-16T03:41:59.961456Z","shell.execute_reply":"2025-05-16T03:42:01.114578Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing Accuracy","metadata":{}},{"cell_type":"code","source":"conf_matrix = confusion_matrix(all_labels_test, all_preds_test)\n\n# Calculate the accuracy for each class\nclass_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n\n# Print the accuracy for each class\nfor i, class_accuracy in enumerate(class_accuracies):\n    print_log(f\"Accuracy for class {i}: {class_accuracy:.6f}\")\n\n\nplt.figure(figsize=(10, 7))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nimage_path = 'confusion_matrix.png'\nplt.savefig(image_path)\nwandb.log({\n    \"confusion_matrix\": wandb.Image(image_path)  # Log the t-SNE plot image\n})\nplt.show()\nprint_log(\"Confusion matrix is create sucessfully using test\")\nwandb.log({\"confusion_matrix_test\": wandb.Image('confusion_matrix.png')})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T03:42:01.116041Z","iopub.execute_input":"2025-05-16T03:42:01.116332Z","execution_failed":"2025-05-16T03:53:49.703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Move each tensor to CPU, detach from computation graph, and convert to NumPy array\nfeature_embeddings_cpu = [emb.cpu().detach().numpy() for emb in feature_embeddings]\n\n# Check for NaNs in individual arrays\nfor i, emb_np in enumerate(feature_embeddings_cpu):\n    if np.isnan(emb_np).any():\n        print_log(f\"NaN detected in feature_embeddings_cpu at index {i}\")\n\n# Concatenate the list of numpy arrays into a single numpy array\nfeature_embeddings_np = np.concatenate(feature_embeddings_cpu, axis=0)\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Map activities to IDs with sequential keys from 0 to len(all_list)-1\nactivity_id_mapping = {idx: activity for idx, activity in enumerate(activity_names)}\n\n# Output the results\n# print(\"Shuffled Activity Names:\", activity_names)\nprint(\"Activity ID Mapping:\", activity_id_mapping)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate metrics for each class\nresults_df = pd.DataFrame(columns=columns)\naccuracy_list = []\nclass_names = []\nprecision_list = []\nrecall_list = []\nf1_list = []\nfor class_id, class_name in activity_id_mapping.items():\n    # Get the true positive (diagonal) for the class and sum of the row (total samples for that class)\n    true_positive = conf_matrix[class_id, class_id]\n    total_samples = conf_matrix[class_id].sum()\n\n    # Accuracy per class (True positives / Total samples in class)\n    accuracy = true_positive / total_samples if total_samples > 0 else 0\n    \n    # Calculate precision, recall, and F1 score for the current class\n    precision = precision_score(all_labels_test, all_preds_test, labels=[class_id], average='weighted', zero_division=0)\n    recall = recall_score(all_labels_test, all_preds_test, labels=[class_id], average='weighted', zero_division=0)\n    f1 = f1_score(all_labels_test, all_preds_test, labels=[class_id], average='weighted', zero_division=0)\n\n    # Append results to respective lists\n    class_names.append(class_name)\n    accuracy_list.append(accuracy)\n    precision_list.append(precision)\n    recall_list.append(recall)\n    f1_list.append(f1)\n\n# Calculate the average across all classes (macro average)\naverage_accuracy = sum(accuracy_list) / len(accuracy_list)\naverage_precision = sum(precision_list) / len(precision_list)\naverage_recall = sum(recall_list) / len(recall_list)\naverage_f1 = sum(f1_list) / len(f1_list)\n\n# Append the average values to the lists\nclass_names.append('Average')\naccuracy_list.append(average_accuracy)\nprecision_list.append(average_precision)\nrecall_list.append(average_recall)\nf1_list.append(average_f1)\n\n# Create a DataFrame to store the results\nresults_df = pd.DataFrame({\n    'Class': class_names,\n    'Accuracy': accuracy_list,\n    'Precision': precision_list,\n    'Recall': recall_list,\n    'F1-score': f1_list\n})\n\n# Save the results to CSV\nresults_df.to_csv('class_precision_recall_f1.csv', index=False)\n\n# Display the final table\nresults_df","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Example feature embeddings and corresponding labels\n# Replace these with your actual feature embeddings and labels\nembeddings = feature_embeddings_np  # 100 samples, 128-dimensional embeddings\nlabels =np.stack(all_labels_test, axis=0) # 100 samples, 10 different classes\n\n# Apply t-SNE\ntsne = TSNE(n_components=2, random_state=42)\nembeddings_2d = tsne.fit_transform(embeddings)\n\n# Plot t-SNE result\nplt.figure(figsize=(10, 3))\nscatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap='viridis', alpha=0.7)\nplt.colorbar(scatter, label='Class Label')\nplt.title('t-SNE Visualization of Feature Embeddings')\nplt.xlabel('t-SNE Component 1')\nplt.ylabel('t-SNE Component 2')\nimage_path = 'tsne_plot.png'\nplt.savefig(image_path)\n\n# Log the image to wandb\nwandb.log({\n    \"tsne_plot\": wandb.Image(image_path)  # Log the t-SNE plot image\n})\nplt.show()\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\n\n# Initialize dictionary to collect feature embeddings per true label\nembedding_dict = defaultdict(list)\n\nfor batch_idx_t, item_t in enumerate(test_dataloader):\n    with torch.no_grad():\n        item_t_in, class_label = item_t\n        true_labels = class_label\n\n        # Forward pass through the model\n        item_out = test_model(item_t_in.float()[:, :, :feature_length],item_t_in.float()[:, :, feature_length:feature_length*2],item_t_in.float()[:, :, 2*feature_length:])\n\n        class_scores = item_out[0]\n        feature_embedding = item_out[1]  # Shape: [batch_size, embedding_dim]\n\n        # Append predictions and labels for evaluation\n        predicted_classes = torch.argmax(class_scores, dim=1)\n        all_preds_test.extend(predicted_classes.tolist())\n        all_labels_test.extend(true_labels.tolist())\n\n        # Store embeddings per true label\n        for emb, label in zip(feature_embedding, true_labels):\n            embedding_dict[label.item()].append(emb.cpu())\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Convert each list of tensors to a NumPy array\nembedding_dict_np = {\n    label: np.stack([emb.numpy() for emb in embeddings])\n    for label, embeddings in embedding_dict.items()\n}\n\n# Save the dictionary as a .npy file\nnp.save(\"feature_embeddings.npy\", embedding_dict_np)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Load the file\nfile_path = \"/kaggle/working/feature_embeddings.npy\"\nimu_data = np.load(file_path, allow_pickle=True)\n\n# Extract the actual object if it's a dictionary or similar\nimu_data = imu_data.item()  # This works if the saved object is a dict or list\n\n# Check what keys it has\nprint(f\"Type: {type(imu_data)}\")\nprint(f\"Keys: {imu_data.keys()}\")\n\n# Example: Access embeddings and labels if present\nif 'embeddings' in imu_data and 'labels' in imu_data:\n    embeddings = imu_data['embeddings']\n    labels = imu_data['labels']\n    \n    print(f\"Embeddings shape: {np.array(embeddings).shape}\")\n    print(f\"Labels: {labels[:5]}\")\n# Check the type and size of one class's embeddings\nsample_key = 0\nsample_value = imu_data[sample_key]\n\nprint(f\"Type of imu_data[{sample_key}]: {type(sample_value)}\")\n\n# If it's a list or array, show the shape and a sample\nif isinstance(sample_value, (list, np.ndarray)):\n    sample_array = np.array(sample_value)\n    print(f\"Shape of imu_data[{sample_key}]: {sample_array.shape}\")\n    # print(f\"Sample embedding:\\n{sample_array[0]}\")\nelse:\n    print(f\"Unexpected format: {sample_value}\")\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Small testing for visualization","metadata":{}},{"cell_type":"code","source":"cross_sensor = [\"HC\", \"HA\", \"CH\", \"CA\", \"AH\", \"AC\"]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testing_data_batches = {}  # Use a dictionary to store batches by key\n\nfor i in range(len(testing_data)):\n    # Extract specific samples\n    subset_samples = testing_data[i][0:2]  # Get the first two rows\n    subset_samples = [row[0:4] for row in subset_samples]  # Get the first 10 elements of each row\n    testing_data_batches[f'batch_{i}'] = subset_samples\n    print(f\"Subset samples: {np.array(subset_samples).shape}, {i, 'i'}\")  # Check the shape\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testing_data=[]\nfor batch_key, batch_data in testing_data_batches.items():\n    print(f\"Processing {batch_key}: Shape of batch data {np.array(batch_data).shape}\")\n    testing_data.append(batch_data)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"testing_data=testing_data\ntest_dataset = TestDataset(testing_data)\ntest_dataloader = DataLoader(test_dataset, batch_size=8)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_embeddings = []\nall_preds_test = []\nall_labels_test = []\ntest_model = torch.load(final_best_model)\ntest_model.eval()\ntest_model.train(False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"overall_test=[]\nfor batch_idx_t, item_t in enumerate(test_dataloader):\n    with torch.no_grad():\n\n        item_t_in,class_label=item_t\n\n        true_labels=class_label\n\n        item_out = test_model(item_t_in.float()[:, :, :feature_length],item_t_in.float()[:, :, feature_length:feature_length*2],item_t_in.float()[:, :, 2*feature_length:])\n        class_scores=item_out[0]\n        feature_embeddings.append(item_out[1])\n        attention_matrix_test=item_out[5]\n        overall_test.append(attention_matrix_test)\n        predicted_classes = torch.argmax(class_scores, dim=1)\n        all_preds_test.extend(predicted_classes.tolist())\n        all_labels_test.extend(true_labels.tolist())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for batch in overall_test:\n#     print(batch.shape)\n#     batch=batch.transpose(0,1)\n#     print(batch.shape)\n#     for i in range(8):\n#         print(batch[i].shape)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# for batch_idx, batch in enumerate(overall_test):\n#     batch = batch.transpose(0, 1)\n    \n#     for i in range(8):\n#         values = batch[i].cpu().numpy()  # Move to CPU and convert to numpy array\n#         values = values.squeeze()  # Ensure it's 1D\n        \n#         plt.figure(figsize=(8, 4))\n#         plt.bar(range(len(values)), values)  # Use bar plot\n#         plt.title(f\"Batch {batch_idx}, Index {i}\")\n#         plt.xlabel(\"Index\")\n#         plt.ylabel(\"Value\")\n#         plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cross_sensor = [\"HC\", \"HA\", \"CH\", \"CA\", \"AH\", \"AC\"]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor batch_idx, batch in enumerate(overall_test):\n    batch = batch.transpose(0, 1)\n    class_name = activity_id_mapping[batch_idx]\n    for i in range(8):\n        values = batch[i]  # Move to CPU and convert to numpy array\n        values = values.squeeze()  # Ensure it's 1D\n        print(values)\n        matrix = torch.zeros(3, 3)\n        matrix[0, 1] = values[0]  # Row 0, Col 1\n        matrix[0, 2] = values[1]  # Row 0, Col 2\n        matrix[1, 0] = values[2]  # Row 1, Col 0\n        matrix[1, 2] = values[3]  # Row 1, Col 2\n        matrix[2, 0] = values[4]  # Row 2, Col 0\n        matrix[2, 1] = values[5]  # Row 2, Col 1\n        print(\"3x3 Matrix:\\n\", matrix)\n        \n        # Visualize the matrix as a heatmap\n        plt.figure(figsize=(6, 6))\n        sns.heatmap(matrix.cpu().numpy(), annot=True, fmt=\".2f\", cmap=\"viridis\", square=True,xticklabels=[\"H\", \"C\", \"A\"], yticklabels=[\"H\", \"C\", \"A\"] )\n        plt.title(f\"Cross Sensor Attention - {class_name}\")\n        plt.xlabel(\"Placement - Query\")\n        plt.ylabel(\"Placement - Key\")\n        plt.show()\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from matplotlib.colors import ListedColormap\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nimport numpy as np\n\n# Create a colormap with black for masked values\ncmap = sns.color_palette(\"viridis\", as_cmap=True)\ncmap.set_bad(color=\"#FFFFFF\")  # Set the diagonal (masked) values to white\n\nfor batch_idx, batch in enumerate(overall_test):\n    batch = batch.transpose(0, 1)\n    class_name = activity_id_mapping[batch_idx]\n    for i in range(8):\n        values = batch[i]\n        values = values.squeeze()  # Ensure it's 1D\n        print(values)\n\n        # Create 3x3 matrix\n        matrix = torch.zeros(3, 3, device=values.device)  # Ensure matrix is on the same device as values\n        matrix[0, 1] = values[0]  # Row 0, Col 1\n        matrix[0, 2] = values[1]  # Row 0, Col 2\n        matrix[1, 0] = values[2]  # Row 1, Col 0\n        matrix[1, 2] = values[3]  # Row 1, Col 2\n        matrix[2, 0] = values[4]  # Row 2, Col 0\n        matrix[2, 1] = values[5]  # Row 2, Col 1\n\n        print(\"3x3 Matrix:\\n\", matrix)\n\n        # Mask the diagonal\n        mask = torch.eye(3, device=values.device).bool()  # Mask for the diagonal (on the same device as matrix)\n        matrix_np = matrix.cpu().numpy()  # Convert matrix to NumPy (move to CPU)\n        mask_np = mask.cpu().numpy()  # Convert mask to NumPy (move to CPU)\n        matrix_np[mask_np] = np.nan  # Set diagonal values to NaN\n\n        # Visualize the heatmap\n        plt.figure(figsize=(10, 3))\n        ax = sns.heatmap(\n            matrix_np, \n            annot=True, \n            fmt=\".2f\", \n            cmap=cmap,  # Use custom colormap\n            square=True,\n            xticklabels=[\"H\", \"C\", \"A\"], \n            yticklabels=[\"H\", \"C\", \"A\"], \n            mask=mask_np,  # Use the mask\n            cbar_kws={\"label\": \"Attention Weight\"},  # Add color bar label\n            linewidths=0.5,  # Add gridlines for the cells\n            linecolor=\"grey\"  # Set gridline color to grey for the background\n        )\n\n        # Add a grey background behind the heatmap\n        ax.set_facecolor(\"#D3D3D3\")  # Set facecolor for areas outside heatmap\n        ax.figure.patch.set_facecolor(\"#D3D3D3\")  # Set the overall figure background color\n        plt.title(f\"Cross Sensor Attention - {class_name}\")\n        plt.xlabel(\"Placement - Query\")\n        plt.ylabel(\"Placement - Key\")\n        plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.finish()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T03:53:49.707Z"}},"outputs":[],"execution_count":null}]}